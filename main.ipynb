{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeGame(gym.Env):\n",
    "    # other metadata avail, render.moldes unncessary if render() is not implemented\n",
    "    metadata = {'render.modes' : ['console', 'rgb_array']}\n",
    "\n",
    "    n_actions = 3\n",
    "\n",
    "    # actions\n",
    "    LEFT = 0\n",
    "    STRAIGHT = 1\n",
    "    RIGHT = 2\n",
    "\n",
    "    # states\n",
    "    EMPTY = 0\n",
    "    SNAKE = 1\n",
    "    WALL = 2\n",
    "    FOOD = 3\n",
    "\n",
    "    REWARD_WALL_HIT = -20\n",
    "    REWARD_PER_STEP_TOWARDS_FOOD = 1 # avoid hitting walls on purpose\n",
    "    REWARD_PER_FOOD = 50\n",
    "    MAX_STEPS_AFTER_FOOD = 200 # avoid loop\n",
    "\n",
    "\n",
    "    def grid_distance(self, pos1, pos2):\n",
    "        # calculate euclidean distance between 2 points\n",
    "        return np.linalg.norm(np.array(pos1, dtype=np.float32) - np.array(pos2, dtype=np.float32))\n",
    "    \n",
    "    \n",
    "    def __init__(self, grid_size=10):\n",
    "        super(SnakeGame, self).__init__()\n",
    "\n",
    "        # steps init\n",
    "        self.stepnum = 0\n",
    "        self.last_food_step = 0\n",
    "\n",
    "        # grid init\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = np.zeros((self.grid_size, self.grid_size), dtype=np.uint8) + self.EMPTY # EMPTY is zero so it doesn't matter (in case its not)\n",
    "        \n",
    "        # wall init\n",
    "        self.grid[0, :] = self.WALL # UP\n",
    "        self.grid[:, 0] = self.WALL # LEFT\n",
    "        self.grid[self.grid_size - 1, :] # DOWN\n",
    "        self.grid[:, self.grid_size - 1] # RIGHT\n",
    "\n",
    "        # snake init\n",
    "        self.snake_coord = [(1, 1), (2, 1)] # top left\n",
    "\n",
    "        for coord in self.snake_coord:\n",
    "            self.grid[coord] - self.SNAKE\n",
    "\n",
    "        # food init\n",
    "        self.grid[3, 3] = self.FOOD\n",
    "\n",
    "        # distance calculation\n",
    "        self.head_dist_to_food = self.grid_distance(\n",
    "            self.snake_coord[-1],\n",
    "            np.argwhere(self.grid == self.FOOD)[0]\n",
    "        )\n",
    "\n",
    "        # save init setup\n",
    "        self.init_grid = self.grid.copy()\n",
    "        self.init_snake_coord = self.snake_coord.copy()\n",
    "\n",
    "        # action space\n",
    "        self.action_space = spaces.Discrete(self.n_actions)\n",
    "\n",
    "        # observation(state) space\n",
    "        self.observation_space = spaces.Dict(\n",
    "            spaces={\n",
    "                \"position\" : spaces.Box(low=0, high=(self.grid_size - 1), shape=(2,), dtype=np.int32),\n",
    "                \"direction\" : spaces.Box(low=-1, high=1, shape=(2,), dtype=np.int32),\n",
    "                \"grid\" : spaces.Box(low=0, high=3, shape=(self.grid_size, self.grid_size), dtype=np.uint8)\n",
    "            }\n",
    "        )\n",
    "    \n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        # to init position\n",
    "        self.stepnum = 0\n",
    "        self.last_food_step = 0\n",
    "        self.grid = self.init_grid.copy()\n",
    "        self.snake_coord = self.init_snake_coord.copy()\n",
    "\n",
    "        self.head_dist_to_food = self.grid_distance(\n",
    "            self.snake_coord[-1],\n",
    "            np.argwhere(self.grid == self.FOOD)[0]\n",
    "        )\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        obs = self._get_obs() # state space\n",
    "        info = {}\n",
    "\n",
    "        return obs, info\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        position = np.array(self.snake_coord[-1], dtype=np.int32)\n",
    "        direction = (np.array(self.snake_coord[-1]) - np.array(self.snake_coord[-2])).astype(np.int32)\n",
    "        grid = self.grid \n",
    "\n",
    "        obs = {\n",
    "            \"position\" : position,\n",
    "            \"direction\" : direction,\n",
    "            \"grid\" : grid\n",
    "        }\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "\n",
    "    def step(self, action):\n",
    "        direction = np.array(self.snake_coord[-1]) - np.array(self.snake_coord[-2])\n",
    "\n",
    "        if action == self.STRAIGHT:\n",
    "            step = direction # towards the direction the snake faces\n",
    "        elif action == self.RIGHT:\n",
    "            # rotation matrix\n",
    "            step = np.array( [direction[1], -direction[0]] )\n",
    "        elif action == self.LEFT:\n",
    "            step = np.array( [-direction[1], direction[0]] )\n",
    "        \n",
    "        # new head\n",
    "        new_coord = (np.array(self.snake_coord[-1]) + step).astype(np.int32)\n",
    "        self.snake_coord.append( (new_coord[0], new_coord[-1]) )\n",
    "\n",
    "        new_pos = self.snake_coord[-1]\n",
    "        new_pos_type = self.grid[new_pos]\n",
    "        self.grid[new_pos] = self.SNAKE\n",
    "\n",
    "        done = False\n",
    "        reward = 0 # calculated later\n",
    "\n",
    "        if new_pos_type == self.FOOD:\n",
    "            reward += self.REWARD_PER_FOOD\n",
    "            self.last_food_step = self.stepnum\n",
    "\n",
    "            # new food\n",
    "            empty_tiles = np.argwhere(self.grid == self.EMPTY)\n",
    "\n",
    "            if len(empty_tiles):\n",
    "                new_food_pos = empty_tiles[np.random.randint(0, len(empty_tiles))]\n",
    "                self.grid[new_food_pos[0], new_food_pos[1]] = self.FOOD\n",
    "            else:\n",
    "                done = True\n",
    "        else:\n",
    "            self.grid[self.snake_coord[0]] = self.EMPTY # empty the snake tail\n",
    "            self.snake_coord = self.snake_coord[1:]\n",
    "\n",
    "            if (new_pos_type == self.WALL) or (new_pos_type == self.SNAKE):\n",
    "                done = True\n",
    "                reward += self.REWARD_WALL_HIT\n",
    "        \n",
    "        head_dist_to_food_prev = self.head_dist_to_food\n",
    "        self.head_dist_to_food = self.grid_distance(\n",
    "            self.snake_coord[-1],\n",
    "            np.argwhere(self.grid == self.FOOD)[0]\n",
    "        )\n",
    "\n",
    "        # reward for distance between snake <-> food\n",
    "        if head_dist_to_food_prev > self.head_dist_to_food:\n",
    "            reward += self.REWARD_PER_STEP_TOWARDS_FOOD\n",
    "        elif head_dist_to_food_prev < self.head_dist_to_food:\n",
    "            reward -= self.REWARD_PER_STEP_TOWARDS_FOOD\n",
    "        \n",
    "        # max steps since no food\n",
    "        if ((self.stepnum - self.last_food_step) > self.MAX_STEPS_AFTER_FOOD):\n",
    "            done = True\n",
    "        \n",
    "        self.stepnum += 1\n",
    "\n",
    "        # return observation, reward, done, truncated, info\n",
    "        return self._get_obs(), reward, done, False, {}\n",
    "\n",
    "\n",
    "    def snake_plot(self, plot_inline=False):\n",
    "        wall_idx = (self.grid == self.WALL)\n",
    "        snake_idx = (self.grid == self.SNAKE)\n",
    "        food_idx = (self.grid == self.FOOD)\n",
    "\n",
    "        # colour array for plot\n",
    "        colour_arr = np.zeros((self.grid_size, self.grid_size, 3), dtype=np.uint8) + 255 # default to white\n",
    "        colour_arr[wall_idx, :] = np.array([0, 0, 0])\n",
    "        colour_arr[snake_idx, :] = np.array([255, 196, 0])\n",
    "        colour_arr[food_idx, :] = np.array([30, 47, 135])\n",
    "\n",
    "        return colour_arr\n",
    "    \n",
    "\n",
    "    def render(self, mode='rgb_array'):\n",
    "        if mode == 'console':\n",
    "            print(self.grid)\n",
    "        elif mode == 'rgb_array':\n",
    "            return self.snake_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/btn8hg2d17q5fc87bd96sbx80000gn/T/ipykernel_6175/3818111661.py:50: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  self.grid[coord] - self.SNAKE\n",
      "/Users/slynj/Documents/Github/RL-snake-game/.venv/lib/python3.12/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: Your observation grid has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# env check\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = SnakeGame()\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import os\n",
    "\n",
    "# log\n",
    "log_dir = \"log\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# env\n",
    "env = SnakeGame()\n",
    "\n",
    "# wrap env with monitor\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "# cb fn -> periodically evaluate the model and save the best version\n",
    "eval_cb = EvalCallback(env, best_model_save_path='./best_model',\n",
    "                       log_path='./log',\n",
    "                       eval_freq=5000,\n",
    "                       deterministic=False,\n",
    "                       render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "# Proximal Policy Optimization\n",
    "\n",
    "# PPO hyperparam\n",
    "PPO_model_args = {\n",
    "    \"learning_rate\" : 0.03,\n",
    "    \"gamma\" : 0.6, # discount factor for further rewards [0, 1]\n",
    "    \"verbose\" : 0, # 1 -> more info on training steps\n",
    "    \"seed\" : 523,\n",
    "    \"ent_coef\" : 0.2, # entropy coef -> encourage exploration\n",
    "    \"clip_range\" : 0.2 # limits p of action difference\n",
    "}\n",
    "\n",
    "# Multi Input Policy since we have 1+ states as an 'input'\n",
    "model = PPO('MultiInputPolicy', env, **PPO_model_args)\n",
    "\n",
    "if os.path.exists(\"best_model/best_model.zip\"):\n",
    "    model.set_parameters(\"best_model/best_model.zip\")\n",
    "\n",
    "model.learn(6000000, callback=eval_cb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
